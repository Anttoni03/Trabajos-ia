{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA disponible. PyTorch usará la GPU: NVIDIA GeForce RTX 4080 SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Verificar si CUDA está disponible\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA disponible. PyTorch usará la GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA no está disponible. PyTorch usará la CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T13:14:20.305335Z",
     "start_time": "2024-10-24T13:14:13.070162Z"
    },
    "id": "FaadnhbpCcsh"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ly7lrx-gCuLy"
   },
   "source": [
    "# Xarxes convolucionals multiclasse\n",
    "\n",
    "Aquesta pràctica està enfocada en l'extensió dels conceptes apresos anteriorment sobre les xarxes neuronals convolucionals (CNN) aplicades a la classificació binària. En la sessió passada, vam treballar amb problemes de classificació on només hi havia dues categories possibles. Ara farem un pas més endavant i ens centrarem en els problemes de classificació multiclasse, on un conjunt de dades pot tenir més de dues classes o categories possibles.\n",
    "\n",
    "L'objectiu d'aquesta pràctica és entendre com les CNN poden adaptar-se a problemes multiclasse, i com els canvis en l'arquitectura, la funció de pèrdua i el processament de sortida permeten gestionar aquesta complexitat addicional. A més, explorarem les estratègies més adequades per a l'entrenament de models en aquest context, i veurem com interpretar els resultats obtinguts en un escenari amb múltiples categories.\n",
    "\n",
    "Aquesta pràctica proporcionarà una base sòlida per abordar problemes de classificació en aplicacions reals, com ara el reconeixement d'imatges amb més d'una etiqueta possible.\n",
    "\n",
    "## Dades\n",
    "\n",
    "El conjunt de dades [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) és una versió alternativa al MNIST, que consisteix en imatges de roba en lloc de dígits escrits a mà. És un conjunt de dades de classificació multiclasse molt utilitzat per a tasques d'aprenentatge automàtic i visió per computador, i s'ha convertit en un estàndard per provar models de xarxes neuronals.\n",
    "\n",
    "El conjunt conté un total de 70.000 imatges en escala de grisos, cadascuna amb una mida de 28x28 píxels, distribuïdes en 10 categories diferents de peces de vestir, com per exemple samarretes, pantalons, sabates, i altres articles de moda. Hi ha 60.000 imatges per a entrenament i 10.000 per a proves.\n",
    "\n",
    "Cada imatge està etiquetada amb un valor entre 0 i 9, que correspon a un tipus de roba.\n",
    "\n",
    "![Exemples de Fashion MNIST](https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/doc/img/fashion-mnist-sprite.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T13:15:28.231318Z",
     "start_time": "2024-10-24T13:15:24.866472Z"
    },
    "id": "PwSoPhjXCvV9"
   },
   "outputs": [],
   "source": [
    "DOWNLOAD = True\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "train= datasets.FashionMNIST(\"../data\", train=True, download=DOWNLOAD, transform=transform)\n",
    "test=datasets.FashionMNIST(\"../data\", train=False, download=DOWNLOAD, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, BATCH_SIZE)\n",
    "test_loader = torch.utils.data.DataLoader(test, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T13:15:28.497798Z",
     "start_time": "2024-10-24T13:15:28.450472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "img, target = next(iter(train_loader))\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definició de la xarxa\n",
    "\n",
    "En primer lloc, declaram una xarxa (CNN) partim de la que vàreu emprar ahir amb en Biel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T13:26:55.827847Z",
     "start_time": "2024-10-24T13:26:55.818839Z"
    }
   },
   "outputs": [],
   "source": [
    "model_cnn = nn.Sequential(\n",
    "    torch.nn.Conv2d(in_channels= 1, out_channels= 4, kernel_size=(3,3), stride=1, padding=\"same\"),\n",
    "    torch.nn.MaxPool2d(kernel_size=(2,2)),\n",
    "    torch.nn.ReLU(),\n",
    "\n",
    "    torch.nn.Conv2d(in_channels= 4, out_channels= 8, kernel_size=(3,3), stride=1, padding=\"same\"),\n",
    "    torch.nn.MaxPool2d(kernel_size=(2,2)),\n",
    "    torch.nn.ReLU(),\n",
    "\n",
    "    torch.nn.Flatten(1),\n",
    "\n",
    "    torch.nn.Linear(392, 10),\n",
    "    nn.ReLU(),\n",
    "    torch.nn.Linear(10, 10),\n",
    "    nn.ReLU(),\n",
    "    torch.nn.Linear(10, 10),\n",
    ").to(\"cuda\")\n",
    "\n",
    "#model_cnn.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8i4Mg8KuD3r"
   },
   "source": [
    "**Per poder resoldre el problema d'avui s'ha de modificar**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenament CNN\n",
    "\n",
    "Ara partint de l'entrenament d'ahir heu d'adaptar-lo a multiclasse. Per fer-ho hem de canviar tot un conjunt d'elements:\n",
    "\n",
    "-   **Funció de pèrdua**. La funció de pèrdua que hem emprat fins ara està especialment dissenyada per problemes binaris hem trobar-ne una que serveixi per multiclasse. La funció que hem emprat [``BCEWithLogits``](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html) (binary cross entropy) a més té una peculiaritat: inclou una funció Sigmoide. A la plana de [pytorch](https://pytorch.org/docs/stable/nn.html#loss-functions) podreu veure totes les funcions de pèrdua que hi ha.\n",
    "-   **Sortida de la xarxa**. La xarxa ha de retornar una codificació adequada per més de dues classes.\n",
    "\n",
    "Les funcions sigmoide i softmax són dues funcions d'activació molt utilitzades en xarxes neuronals, especialment en tasques de classificació, però tenen aplicacions diferents\n",
    "segons el tipus de problema.\n",
    "\n",
    "### Funció Sigmoide\n",
    "\n",
    "La funció sigmoide es defineix com:\n",
    "\n",
    "$$\\sigma(X) = \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "**Aquesta funció pren qualsevol valor real d'entrada i el transforma en un valor comprès entre 0 i 1.** Per aquest motiu, s'utilitza principalment en problemes de classificació binària, on l'objectiu és assignar una de dues possibles classes. La sortida de la funció sigmoide es pot interpretar com una probabilitat, fent que sigui especialment útil per a la sortida d'una xarxa neuronal en problemes on es busca predir una classe binària (0 o 1).\n",
    "\n",
    "### Funció Softmax\n",
    "\n",
    "La funció softmax s'utilitza en problemes de classificació multiclasse. Aquesta funció pren un vector d'entrades (generalment els valors generats a la sortida d'una capa final d'una xarxa neuronal) i el transforma en una distribució de probabilitats, assegurant que la suma de les probabilitats sigui igual a 1. La seva fórmula és:\n",
    "\n",
    "$$SM(x_i) = \\frac{e^x_i}{\\sum^n_{j=1} e^{x_j}}$$\n",
    "\n",
    "Aquí, $x_i$ és un dels valors de la sortida, i la funció calcula la probabilitat de cada classe relativa a les altres. Això fa que softmax sigui ideal per a problemes de classificació amb múltiples categories, ja que converteix els valors de la sortida en probabilitats que es poden utilitzar per predir quina és la classe més probable.\n",
    "\n",
    "En resum:\n",
    "\n",
    "- Sigmoide: útil per a classificació binària, genera una sortida entre 0 i 1.\n",
    "- Softmax: s'utilitza en classificació multiclasse, distribueix probabilitats entre totes les classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T13:26:58.066019Z",
     "start_time": "2024-10-24T13:26:58.060514Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-3  # Hiperparàmetre\n",
    "optimizer = optim.Adam(model_cnn.parameters(), lr=learning_rate)\n",
    "\n",
    "running_loss = []\n",
    "running_acc = []\n",
    "\n",
    "running_test_loss = []\n",
    "running_test_acc_cnn = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T13:28:17.954897Z",
     "start_time": "2024-10-24T13:27:00.330648Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299a13ae8fb94ca88bd300d4f0d90943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Èpoques:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec590659958429b8898bdbb0328c997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches (Època 1): 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2bf07b2096f4de19b9afca9f748c5ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches (Època 2): 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef7a7b99baac4669822c076644b74eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches (Època 3): 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9bcfba5460645e3a357b93872a07bf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches (Època 4): 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a01819fad0642a5b83b3634b4fc5635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches (Època 5): 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for t in tqdm(range(EPOCHS), desc=\"Èpoques\"):\n",
    "    batch_loss = 0\n",
    "    batch_acc = 0\n",
    "    \n",
    "    i_batch = 1\n",
    "    # Iteram els batches.\n",
    "    for i_batch, (x, y) in tqdm(enumerate(train_loader), desc=f\"Batches (Època {t + 1})\"):\n",
    "        model_cnn.train()  # Posam el model a mode entranament.\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 1. PREDICCIÓ\n",
    "\n",
    "        y_pred = model_cnn(x.to('cuda'))\n",
    "        \n",
    "\n",
    "        # 2. CALCUL DE LA PÈRDUA\n",
    "        # Computa la pèrdua: l'error de predicció vs el valor correcte\n",
    "        # Es guarda la pèrdua en un array per futures visualitzacions\n",
    "\n",
    "        loss = loss_fn(y_pred, y.to('cuda'))\n",
    "\n",
    "        #3. GRADIENT\n",
    "        model_cnn.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Actualitza els pesos utilitzant l'algorisme d'actualització\n",
    "        #4. OPTIMITZACIO\n",
    "        with torch.no_grad():\n",
    "            optimizer.step()\n",
    "\n",
    "        # 5. EVALUAM EL MODEL\n",
    "        model_cnn.eval()  # Mode avaluació de la xarxa\n",
    "\n",
    "        batch_loss += (loss_fn(y_pred, y.to('cuda')).detach())\n",
    "        #batch_acc += accuracy_score(torch.argmax(y_pred.to('cuda').detach(), dim=1), y.to('cuda').detach())\n",
    "\n",
    "    running_loss.append(batch_loss / (i_batch + 1))\n",
    "    running_acc.append(batch_acc / (i_batch + 1))\n",
    "\n",
    "    batch_test_loss = 0\n",
    "    batch_test_acc = 0\n",
    "\n",
    "    for i_batch, (x, y) in enumerate(test_loader):\n",
    "\n",
    "        y_pred = model_cnn(x.to('cuda'))\n",
    "        y_pred_binary = (y_pred > 0.5).double()\n",
    "        \n",
    "        batch_test_loss += (loss_fn(y_pred, y.to('cuda')).detach())\n",
    "        #acc = accuracy_score(torch.argmax(y_pred_binary.to('cuda').detach(), dim=1), y.to('cuda').detach())\n",
    "        #batch_test_acc += acc\n",
    "\n",
    "    running_test_loss.append(batch_test_loss / (i_batch + 1))\n",
    "    running_test_acc_cnn.append(batch_test_acc / (i_batch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T13:28:24.193887Z",
     "start_time": "2024-10-24T13:28:24.025901Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss per iteració CNN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(running_loss, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(running_test_loss, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\iaToni2024\\Lib\\site-packages\\matplotlib\\pyplot.py:3794\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3786\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   3787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[0;32m   3788\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3793\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[1;32m-> 3794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[0;32m   3795\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m   3796\u001b[0m         scalex\u001b[38;5;241m=\u001b[39mscalex,\n\u001b[0;32m   3797\u001b[0m         scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[0;32m   3798\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m   3799\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3800\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\iaToni2024\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:1779\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1776\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1777\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1778\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1779\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\iaToni2024\\Lib\\site-packages\\matplotlib\\axes\\_base.py:296\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    295\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_plot_args(\n\u001b[0;32m    297\u001b[0m     axes, this, kwargs, ambiguous_fmt_datakey\u001b[38;5;241m=\u001b[39mambiguous_fmt_datakey)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\iaToni2024\\Lib\\site-packages\\matplotlib\\axes\\_base.py:478\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    476\u001b[0m     y \u001b[38;5;241m=\u001b[39m _check_1d(xy[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 478\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m index_of(xy[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mxaxis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    481\u001b[0m     axes\u001b[38;5;241m.\u001b[39mxaxis\u001b[38;5;241m.\u001b[39mupdate_units(x)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\iaToni2024\\Lib\\site-packages\\matplotlib\\cbook.py:1719\u001b[0m, in \u001b[0;36mindex_of\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m   1717\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1718\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1719\u001b[0m     y \u001b[38;5;241m=\u001b[39m _check_1d(y)\n\u001b[0;32m   1720\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (VisibleDeprecationWarning, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1721\u001b[0m     \u001b[38;5;66;03m# NumPy 1.19 will warn on ragged input, and we can't actually use it.\u001b[39;00m\n\u001b[0;32m   1722\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\iaToni2024\\Lib\\site-packages\\matplotlib\\cbook.py:1411\u001b[0m, in \u001b[0;36m_check_1d\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1405\u001b[0m \u001b[38;5;66;03m# plot requires `shape` and `ndim`.  If passed an\u001b[39;00m\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;66;03m# object that doesn't provide them, then force to numpy array.\u001b[39;00m\n\u001b[0;32m   1407\u001b[0m \u001b[38;5;66;03m# Note this will strip unit information.\u001b[39;00m\n\u001b[0;32m   1408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1409\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m         \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m-> 1411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39matleast_1d(x)\n\u001b[0;32m   1412\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\iaToni2024\\Lib\\site-packages\\numpy\\_core\\shape_base.py:65\u001b[0m, in \u001b[0;36matleast_1d\u001b[1;34m(*arys)\u001b[0m\n\u001b[0;32m     63\u001b[0m res \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ary \u001b[38;5;129;01min\u001b[39;00m arys:\n\u001b[1;32m---> 65\u001b[0m     ary \u001b[38;5;241m=\u001b[39m asanyarray(ary)\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ary\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     67\u001b[0m         result \u001b[38;5;241m=\u001b[39m ary\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\iaToni2024\\Lib\\site-packages\\torch\\_tensor.py:1149\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Loss per iteració CNN\")\n",
    "plt.plot(running_loss, label=\"train\")\n",
    "plt.plot(running_test_loss, label=\"test\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Accuracy per iteració CNN\")\n",
    "plt.plot(running_acc, label=\"train\")\n",
    "plt.plot(running_test_acc_cnn, label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_test_acc_cnn[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjeMWK8cJkqN"
   },
   "source": [
    "## Resultats\n",
    "\n",
    "Aquí visualitzarem els resultats d'aprenentatge de la xarxa. \n",
    "\n",
    "### Feina a fer:\n",
    "\n",
    "1. Adaptar la sortida del model per un problema multiclasse.\n",
    "2. Emprar una funció de pèrdua adequada per un entorn multiclasse.\n",
    "3. Obtenir l'accuracy en aquest entorn multiclasse.\n",
    "\n",
    "\n",
    "*Subplots*\n",
    "\n",
    "Per fer graelles d'imatges podeu empar la funció `subplots`. Més [informació](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
